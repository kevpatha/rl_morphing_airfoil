{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import datetime\n",
    "\n",
    "import IPython\n",
    "import IPython.display\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "#import tensorflow_addons\n",
    "#import tensorflow_probability as tfp\n",
    "\n",
    "mpl.rcParams['figure.figsize'] = (8,6)\n",
    "mpl.rcParams['axes.grid'] = False\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install tensorflow_probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning Data...\n",
      "..data0..\n",
      "..data1..\n",
      "..data2..\n",
      "..data3..\n",
      "..data4..\n",
      "..data5..\n",
      "..data6..\n",
      "..data8..\n",
      "..done cleaning..\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Flex</th>\n",
       "      <th>last_laz</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>751.0</td>\n",
       "      <td>550.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>748.0</td>\n",
       "      <td>550.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>747.0</td>\n",
       "      <td>555.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>747.0</td>\n",
       "      <td>570.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>748.0</td>\n",
       "      <td>572.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Flex  last_laz\n",
       "0  751.0     550.0\n",
       "1  748.0     550.0\n",
       "2  747.0     555.0\n",
       "3  747.0     570.0\n",
       "4  748.0     572.0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col_names = ['Flex', 'Laz', 'st_volt', 'end_volt', 'time_step', 'tot_time']#, 'time_step', 'total_time']\n",
    "\n",
    "data_filepath0 = 'data/MFC_dynamics_data0_step2_range31_shuffle_seed0.csv'\n",
    "data_filepath1 = 'data/MFC_dynamics_data0_step2_range31_shuffle_seed1.csv'\n",
    "data_filepath2 = 'data/MFC_dynamics_data0_step2_range31_shuffle_seed2.csv'\n",
    "data_filepath3 = 'data/MFC_dynamics_data0_step2_range31_shuffle_seed3.csv'\n",
    "data_filepath4 = 'data/MFC_dynamics_data0_step2_range31_shuffle_seed4.csv'\n",
    "data_filepath5 = 'data/MFC_dynamics_data0_step2_range31_shuffle_seed5.csv'\n",
    "data_filepath6 = 'data/MFC_dynamics_data0_step2_range31_shuffle_seed6.csv'\n",
    "#data_filepath7 = 'data/MFC_dynamics_data0_step2_range31_shuffle_seed7.csv'\n",
    "data_filepath8 = 'data/MFC_dynamics_data0_step2_range31_shuffle_seed8.csv'\n",
    "data_filepath9 = 'data/MFC_dynamics_data0_step2_range31_shuffle_seed9.csv'\n",
    "data_filepath10 = 'data/MFC_dynamics_data0_step2_range31_shuffle_seed10.csv'\n",
    "\n",
    "raw_data0 = pd.read_csv(data_filepath0, names=col_names, na_values = '?', comment='\\t', sep=',')\n",
    "raw_data1 = pd.read_csv(data_filepath1, names=col_names, na_values = '?', comment='\\t', sep=',')\n",
    "raw_data2 = pd.read_csv(data_filepath2, names=col_names, na_values = '?', comment='\\t', sep=',')\n",
    "raw_data3 = pd.read_csv(data_filepath3, names=col_names, na_values = '?', comment='\\t', sep=',')\n",
    "raw_data4 = pd.read_csv(data_filepath4, names=col_names, na_values = '?', comment='\\t', sep=',')\n",
    "raw_data5 = pd.read_csv(data_filepath5, names=col_names, na_values = '?', comment='\\t', sep=',')\n",
    "raw_data6 = pd.read_csv(data_filepath6, names=col_names, na_values = '?', comment='\\t', sep=',')\n",
    "#raw_data7 = pd.read_csv(data_filepath7, names=col_names, na_values = '?', comment='\\t', sep=',')\n",
    "raw_data8 = pd.read_csv(data_filepath8, names=col_names, na_values = '?', comment='\\t', sep=',')\n",
    "#test dataset\n",
    "raw_data9 = pd.read_csv(data_filepath9, names=col_names, na_values = '?', comment='\\t', sep=',')\n",
    "raw_data10 = pd.read_csv(data_filepath10, names=col_names, na_values = '?', comment='\\t', sep=',')\n",
    "\n",
    "def clean_data(df):\n",
    "    df = df[df['Flex']<1023]\n",
    "    df = df[df['Laz']>0]\n",
    "    \n",
    "    df['last_laz'] = df['Laz'].shift(periods=1)\n",
    "    df.dropna(subset = ['last_laz'], inplace=True)\n",
    "    \n",
    "    #df['flex_diff'] = df['Flex'].diff()\n",
    "    #df.dropna(subset = ['flex_diff'], inplace=True)\n",
    "    \n",
    "    df.drop('Laz', inplace = True, axis=1)\n",
    "    df.drop('time_step', inplace=True, axis=1)\n",
    "    df.drop('st_volt', inplace=True, axis=1)\n",
    "    df.drop('end_volt', inplace=True, axis=1)\n",
    "    #df.drop('Flex', inplace=True, axis=1)\n",
    "    #df.drop('Laz', inplace=True, axis=1)\n",
    "    df.drop('tot_time', inplace=True, axis = 1)\n",
    "    return df\n",
    "\n",
    "raw_data = []\n",
    "print('Cleaning Data...')\n",
    "data0 = clean_data(raw_data0)\n",
    "raw_data.append(data0)\n",
    "print('..data0..')\n",
    "data1 = clean_data(raw_data1)\n",
    "raw_data.append(data1)\n",
    "print('..data1..')\n",
    "data2 = clean_data(raw_data2)\n",
    "raw_data.append(data2)\n",
    "print('..data2..')\n",
    "data3 = clean_data(raw_data3)\n",
    "raw_data.append(data3)\n",
    "print('..data3..')\n",
    "data4 = clean_data(raw_data4)\n",
    "raw_data.append(data4)\n",
    "print('..data4..')\n",
    "data5 = clean_data(raw_data5)\n",
    "raw_data.append(data5)\n",
    "print('..data5..')\n",
    "data6 = clean_data(raw_data6)\n",
    "raw_data.append(data6)\n",
    "print('..data6..')\n",
    "data8 = clean_data(raw_data8)\n",
    "raw_data.append(data8)\n",
    "print('..data8..')\n",
    "data9 = clean_data(raw_data9)\n",
    "raw_data.append(data9)\n",
    "print('..done cleaning..')\n",
    "\n",
    "cleaned_data = pd.concat(raw_data, axis=0, ignore_index=True)\n",
    "\n",
    "dataset = cleaned_data.copy()\n",
    "df = dataset #dataset[5::6]\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Flex</th>\n",
       "      <td>2409593.0</td>\n",
       "      <td>760.571349</td>\n",
       "      <td>68.733912</td>\n",
       "      <td>612.0</td>\n",
       "      <td>703.0</td>\n",
       "      <td>757.0</td>\n",
       "      <td>818.0</td>\n",
       "      <td>920.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>last_laz</th>\n",
       "      <td>2409593.0</td>\n",
       "      <td>495.819635</td>\n",
       "      <td>225.281801</td>\n",
       "      <td>44.0</td>\n",
       "      <td>297.0</td>\n",
       "      <td>503.0</td>\n",
       "      <td>703.0</td>\n",
       "      <td>890.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              count        mean         std    min    25%    50%    75%    max\n",
       "Flex      2409593.0  760.571349   68.733912  612.0  703.0  757.0  818.0  920.0\n",
       "last_laz  2409593.0  495.819635  225.281801   44.0  297.0  503.0  703.0  890.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe().transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data info for normalizaton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mean = df.mean()\n",
    "df_std = df.std()\n",
    "\n",
    "def normalize_df(df):\n",
    "    df = (df-df_mean)/df_std\n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data windowing\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WindowGenerator():\n",
    "    def __init__(self, input_width, label_width, shift,\n",
    "               train_df, val_df, test_df,\n",
    "               label_columns=None):\n",
    "        # Store the raw data.\n",
    "        self.train_df = train_df\n",
    "        self.val_df = val_df\n",
    "        self.test_df = test_df\n",
    "\n",
    "        # Work out the label column indices.\n",
    "        self.label_columns = label_columns\n",
    "        if label_columns is not None:\n",
    "            self.label_columns_indices = {name: i for i, name in\n",
    "                                    enumerate(label_columns)}\n",
    "        self.column_indices = {name: i for i, name in\n",
    "                           enumerate(train_df.columns)}\n",
    "\n",
    "        # Work out the window parameters.\n",
    "        self.input_width = input_width\n",
    "        self.label_width = label_width\n",
    "        self.shift = shift\n",
    "\n",
    "        self.total_window_size = input_width + shift\n",
    "\n",
    "        self.input_slice = slice(0, input_width)\n",
    "        self.input_indices = np.arange(self.total_window_size)[self.input_slice]\n",
    "\n",
    "        self.label_start = self.total_window_size - self.label_width\n",
    "        self.labels_slice = slice(self.label_start, None)\n",
    "        self.label_indices = np.arange(self.total_window_size)[self.labels_slice]\n",
    "    \n",
    "    def split_window(self, features):\n",
    "        inputs = features[:, self.input_slice, :]\n",
    "        labels = features[:, self.labels_slice, :]\n",
    "        if self.label_columns is not None:\n",
    "            labels = tf.stack([labels[:, :, self.column_indices[name]] \n",
    "                              for name in self.label_columns],\n",
    "                             axis=-1)\n",
    "        \n",
    "        # Slicing doesn't preserve static shape information, so set the shapes\n",
    "        # manually. This way the tf.data.Datasets are easier to inspect.\n",
    "        inputs.set_shape([None, self.input_width, None])\n",
    "        labels.set_shape([None, self.label_width, None])\n",
    "        \n",
    "        return inputs, labels\n",
    "\n",
    "    def __repr__(self):\n",
    "        return '\\n'.join([\n",
    "            f'Total window size: {self.total_window_size}',\n",
    "            f'Input indices: {self.input_indices}',\n",
    "            f'Label indices: {self.label_indices}',\n",
    "            f'Label column name(s): {self.label_columns}'])\n",
    "    \n",
    "    def plot(self, model=None, plot_col='Laz', max_subplots=3):\n",
    "        inputs, labels = self.example\n",
    "        plt.figure(figsize=(12, 8))\n",
    "        plot_col_index = self.column_indices[plot_col]\n",
    "        max_n = min(max_subplots, len(inputs))\n",
    "        for n in range(max_n):\n",
    "            plt.subplot(max_n, 1, n+1)\n",
    "            plt.ylabel(f'{plot_col} [normed]')\n",
    "            plt.plot(self.input_indices, inputs[n, :, plot_col_index],\n",
    "                 label='Inputs', marker='.', zorder=-10)\n",
    "\n",
    "            if self.label_columns:\n",
    "                label_col_index = self.label_columns_indices.get(plot_col, None)\n",
    "            else:\n",
    "                label_col_index = plot_col_index\n",
    "\n",
    "            if label_col_index is None:\n",
    "                continue\n",
    "\n",
    "            plt.scatter(self.label_indices, labels[n, :, label_col_index],\n",
    "                    edgecolors='k', label='Labels', c='#2ca02c', s=64)\n",
    "            if model is not None:\n",
    "                predictions = model(inputs)\n",
    "                plt.scatter(self.label_indices, predictions[n, :, label_col_index],\n",
    "                      marker='X', edgecolors='k', label='Predictions',\n",
    "                      c='#ff7f0e', s=64)\n",
    "\n",
    "            if n == 0:\n",
    "                plt.legend()\n",
    "\n",
    "        plt.xlabel('Time')\n",
    "        \n",
    "    def make_dataset(self, data):\n",
    "        data = np.array(data, dtype=np.float32)\n",
    "        ds = tf.keras.preprocessing.timeseries_dataset_from_array(data=data,\n",
    "                                                                 targets=None,\n",
    "                                                                 sequence_length=self.total_window_size,\n",
    "                                                                 sequence_stride=1,\n",
    "                                                                 shuffle=True,\n",
    "                                                                 batch_size=100,) #was 32\n",
    "        ds = ds.map(self.split_window)\n",
    "        return ds\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "@property\n",
    "def train(self):\n",
    "    return self.make_dataset(self.train_df)\n",
    "\n",
    "@property\n",
    "def val(self):\n",
    "    return self.make_dataset(self.val_df)\n",
    "\n",
    "@property\n",
    "def test(self):\n",
    "    return self.make_dataset(self.test_df)\n",
    "\n",
    "@property\n",
    "def example(self):\n",
    "    \"\"\"Get and cache an example batch of inputs, labels for plotting\"\"\"\n",
    "    result = getattr(self, '_example', None)\n",
    "    if result is None:\n",
    "        # No example batch was found, so get one from the .train dataset\n",
    "        result = next(iter(self.train))\n",
    "        # And cache it for next time\n",
    "        self._example=result\n",
    "    return result\n",
    "\n",
    "WindowGenerator.train = train\n",
    "WindowGenerator.val = val\n",
    "WindowGenerator.test = test\n",
    "WindowGenerator.example = example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_EPOCHS = 100\n",
    "\n",
    "def compile_and_fit(model, window, patience=2):\n",
    "    callback = [tf.keras.callbacks.EarlyStopping(patience=7),\n",
    "                    tf.keras.callbacks.ReduceLROnPlateau(patience=5, verbose=1),\n",
    "                    tf.keras.callbacks.ModelCheckpoint('flex_to_laz_mlp.hdf', save_best_only=True, save_weights_only=True)]\n",
    "    \n",
    "    model.compile(loss=tf.losses.MeanSquaredError(),\n",
    "                 optimizer=tf.optimizers.Adam(learning_rate=1e-4),\n",
    "                 metrics=[tf.metrics.MeanAbsoluteError()])\n",
    "    \n",
    "    history = model.fit(window.train, epochs=MAX_EPOCHS,\n",
    "                       validation_data=window.val,\n",
    "                       callbacks=callback)\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_performance = {}\n",
    "performance = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, dataframe, test, window = False, is_clean=False):\n",
    "    \n",
    "    df = dataframe.copy()\n",
    "    test = test.copy()\n",
    "    \n",
    "    if is_clean:\n",
    "        df = dataframe\n",
    "    else:    \n",
    "        df = clean_data(df)\n",
    "    \n",
    "    test = clean_data(test)\n",
    "    \n",
    "    print(df.tail())\n",
    "    print(test.tail())\n",
    "\n",
    "    \n",
    "    df = normalize_df(df)\n",
    "    test = normalize_df(test)\n",
    "    \n",
    "    col_indices = {name: i for i, name in enumerate(df.columns)}\n",
    "\n",
    "    n = len(df)\n",
    "    train_df = df[:int(0.8*n)]\n",
    "    val_df = df[int(0.8*n):]\n",
    "    test_df = test\n",
    "\n",
    "    num_features = df.shape[1]\n",
    "    \n",
    "    print(f'num features: {num_features}')\n",
    "    \n",
    "    CONV_WIDTH = 10\n",
    "    conv_window = WindowGenerator(input_width=CONV_WIDTH,\n",
    "                                 label_width=1,\n",
    "                                 shift=1,\n",
    "                                 label_columns=['last_laz'],\n",
    "                                 train_df=train_df,\n",
    "                                 val_df=val_df,\n",
    "                                 test_df=test_df)\n",
    "    \n",
    "    history = compile_and_fit(model, conv_window)\n",
    "    model.load_weights('flex_to_laz_mlp.hdf')\n",
    "\n",
    "    if window:\n",
    "        return model, conv_window\n",
    "    else:\n",
    "        return model\n",
    "    \n",
    "  \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi step dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4820/4820 [==============================] - 16s 3ms/step - loss: 4.5306e-04 - mean_absolute_error: 0.0127\n",
      "INFO:tensorflow:Assets written to: MSD_flex_to_laz\\assets\n"
     ]
    }
   ],
   "source": [
    "# Create Model Combined Training\n",
    "\n",
    "                                        #Shape: (time, features) => (time*features)\n",
    "multi_step_dense = tf.keras.Sequential([tf.keras.layers.Flatten(),\n",
    "                                        tf.keras.layers.Dense(units=128, activation='relu'),\n",
    "                                        tf.keras.layers.Dropout(0.2),\n",
    "                                        tf.keras.layers.Dense(units=32, activation='relu'),\n",
    "                                        tf.keras.layers.Dropout(0.2),\n",
    "                                        tf.keras.layers.Dense(units=1),\n",
    "                                        # Add back the time dimension.\n",
    "                                        #Shape: (outputs) => (1, outputs)\n",
    "                                        tf.keras.layers.Reshape([1, -1]),\n",
    "                                       ])\n",
    "\n",
    "\n",
    "\n",
    "#multi_step_dense = train_model(multi_step_dense, raw_data, raw_data5)\n",
    "multi_step_dense, conv_window = train_model(multi_step_dense, cleaned_data, raw_data10, window=True, is_clean=True)\n",
    "\n",
    "IPython.display.clear_output()\n",
    "val_performance['Multi step dense'] = multi_step_dense.evaluate(conv_window.val)\n",
    "performance['Multi step dense'] = multi_step_dense.evaluate(conv_window.test, verbose=0)\n",
    "multi_step_dense.save('MSD_flex_to_laz_X')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "534/534 [==============================] - 2s 3ms/step - loss: 0.0017 - mean_absolute_error: 0.0297\n",
      "INFO:tensorflow:Assets written to: MSD_split_flex_to_laz\\assets\n"
     ]
    }
   ],
   "source": [
    "# Create Model Split Training\n",
    "\n",
    "                                        #Shape: (time, features) => (time*features)\n",
    "multi_step_dense = tf.keras.Sequential([tf.keras.layers.Flatten(),\n",
    "                                        tf.keras.layers.Dense(units=128, activation='relu'),\n",
    "                                        tf.keras.layers.Dropout(0.2),\n",
    "                                        tf.keras.layers.Dense(units=32, activation='relu'),\n",
    "                                        tf.keras.layers.Dropout(0.2),\n",
    "                                        tf.keras.layers.Dense(units=1),\n",
    "                                        # Add back the time dimension.\n",
    "                                        #Shape: (outputs) => (1, outputs)\n",
    "                                        tf.keras.layers.Reshape([1, -1]),\n",
    "                                       ])\n",
    "\n",
    "\n",
    "\n",
    "#multi_step_dense = train_model(multi_step_dense, raw_data, raw_data5)\n",
    "multi_step_dense = train_model(multi_step_dense, raw_data0, raw_data10)\n",
    "multi_step_dense = train_model(multi_step_dense, raw_data1, raw_data10)\n",
    "multi_step_dense = train_model(multi_step_dense, raw_data2, raw_data10)\n",
    "multi_step_dense = train_model(multi_step_dense, raw_data3, raw_data10)\n",
    "multi_step_dense = train_model(multi_step_dense, raw_data4, raw_data10)\n",
    "multi_step_dense = train_model(multi_step_dense, raw_data5, raw_data10)\n",
    "multi_step_dense = train_model(multi_step_dense, raw_data6, raw_data10)\n",
    "#multi_step_dense = train_model(multi_step_dense, raw_data7, raw_data10)\n",
    "multi_step_dense = train_model(multi_step_dense, raw_data8, raw_data10)\n",
    "multi_step_dense, conv_window = train_model(multi_step_dense, raw_data9, raw_data10, window=True)\n",
    "\n",
    "IPython.display.clear_output()\n",
    "val_performance['Multi step dense split'] = multi_step_dense.evaluate(conv_window.val)\n",
    "performance['Multi step dense split'] = multi_step_dense.evaluate(conv_window.test, verbose=0)\n",
    "multi_step_dense.save('MSD_split_flex_to_laz_X')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4820/4820 [==============================] - 14s 3ms/step - loss: 4.9754e-04 - mean_absolute_error: 0.0143\n",
      "INFO:tensorflow:Assets written to: CNN_flex_to_laz\\assets\n"
     ]
    }
   ],
   "source": [
    "# Create model\n",
    "CONV_WIDTH = 10\n",
    "conv_model = tf.keras.Sequential([tf.keras.layers.Conv1D(filters=128,\n",
    "                                                        kernel_size=(CONV_WIDTH,),\n",
    "                                                        activation='relu'),\n",
    "                                  tf.keras.layers.Dropout(0.2),\n",
    "                                  tf.keras.layers.Dense(units=32, activation='relu'),\n",
    "                                  tf.keras.layers.Dropout(0.2),\n",
    "                                  tf.keras.layers.Dense(units=1),\n",
    "                                  tf.keras.layers.Reshape([1, -1]),\n",
    "                                 ])\n",
    "\n",
    "conv_model, conv_window = train_model(conv_model, cleaned_data, raw_data10, window=True, is_clean=True)\n",
    "\n",
    "IPython.display.clear_output()\n",
    "val_performance['CNN'] = conv_model.evaluate(conv_window.val)\n",
    "performance['CNN'] = conv_model.evaluate(conv_window.test, verbose=0)\n",
    "conv_model.save('CNN_flex_to_laz_X')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "534/534 [==============================] - 2s 3ms/step - loss: 4.1250e-04 - mean_absolute_error: 0.0132\n",
      "INFO:tensorflow:Assets written to: CNN_split_flex_to_laz\\assets\n"
     ]
    }
   ],
   "source": [
    "# Create model\n",
    "CONV_WIDTH = 10\n",
    "conv_model = tf.keras.Sequential([tf.keras.layers.Conv1D(filters=128,\n",
    "                                                        kernel_size=(CONV_WIDTH,),\n",
    "                                                        activation='relu'),\n",
    "                                  tf.keras.layers.Dropout(0.2),\n",
    "                                  tf.keras.layers.Dense(units=32, activation='relu'),\n",
    "                                  tf.keras.layers.Dropout(0.2),\n",
    "                                  tf.keras.layers.Dense(units=1),\n",
    "                                  tf.keras.layers.Reshape([1, -1]),\n",
    "                                 ])\n",
    "\n",
    "conv_model = train_model(conv_model, raw_data0, raw_data10)\n",
    "conv_model = train_model(conv_model, raw_data1, raw_data10)\n",
    "conv_model = train_model(conv_model, raw_data2, raw_data10)\n",
    "conv_model = train_model(conv_model, raw_data3, raw_data10)\n",
    "conv_model = train_model(conv_model, raw_data4, raw_data10)\n",
    "conv_model = train_model(conv_model, raw_data5, raw_data10)\n",
    "conv_model = train_model(conv_model, raw_data6, raw_data10)\n",
    "#conv_model = train_model(conv_model, raw_data7, raw_data10)\n",
    "conv_model = train_model(conv_model, raw_data8, raw_data10)\n",
    "conv_model, conv_window = train_model(conv_model, raw_data9, raw_data10, window=True)\n",
    "\n",
    "IPython.display.clear_output()\n",
    "val_performance['CNN split'] = conv_model.evaluate(conv_window.val)\n",
    "performance['CNN split'] = conv_model.evaluate(conv_window.test, verbose=0)\n",
    "conv_model.save('CNN_split_flex_to_laz_X')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4820/4820 [==============================] - 32s 7ms/step - loss: 2.7145e-04 - mean_absolute_error: 0.0083\n",
      "WARNING:tensorflow:From C:\\Users\\Kptha\\Anaconda3\\envs\\tf_torch\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "WARNING:tensorflow:From C:\\Users\\Kptha\\Anaconda3\\envs\\tf_torch\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "INFO:tensorflow:Assets written to: LSTM_flex_to_laz\\assets\n"
     ]
    }
   ],
   "source": [
    "# Create Model\n",
    "CONV_WIDTH = 10\n",
    "                                # Shape [batch, time, features] +> [batch, time, lstm_units]\n",
    "lstm_model = tf.keras.models.Sequential([tf.keras.layers.LSTM(128, return_sequences=False, input_shape=(CONV_WIDTH,2) ),\n",
    "                                            # Shape => [batch, time, features]\n",
    "                                            tf.keras.layers.Dense(units=1),\n",
    "                                            #tf.keras.layers.Reshape([1, -1]),\n",
    "                                            ])\n",
    "\n",
    "\n",
    "lstm_model, conv_window = train_model(lstm_model, cleaned_data, raw_data10, window=True, is_clean=True)\n",
    "\n",
    "IPython.display.clear_output()\n",
    "val_performance['LSTM'] = lstm_model.evaluate(conv_window.val)\n",
    "performance['LSTM'] = lstm_model.evaluate(conv_window.test, verbose=0)\n",
    "\n",
    "lstm_model.save('LSTM_flex_to_laz_X')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "534/534 [==============================] - 3s 6ms/step - loss: 2.5268e-04 - mean_absolute_error: 0.0083\n",
      "INFO:tensorflow:Assets written to: LSTM_split_flex_to_laz\\assets\n"
     ]
    }
   ],
   "source": [
    "# Create Model\n",
    "CONV_WIDTH = 10\n",
    "                                # Shape [batch, time, features] +> [batch, time, lstm_units]\n",
    "lstm_model = tf.keras.models.Sequential([tf.keras.layers.LSTM(128, return_sequences=False, input_shape=(CONV_WIDTH, 2) ),\n",
    "                                            # Shape => [batch, time, features]\n",
    "                                            tf.keras.layers.Dense(units=1),\n",
    "                                            tf.keras.layers.Reshape([1, -1]),\n",
    "                                            ])\n",
    "\n",
    "lstm_model = train_model(lstm_model, raw_data0, raw_data10)\n",
    "lstm_model = train_model(lstm_model, raw_data1, raw_data10)\n",
    "lstm_model = train_model(lstm_model, raw_data2, raw_data10)\n",
    "lstm_model = train_model(lstm_model, raw_data3, raw_data10)\n",
    "lstm_model = train_model(lstm_model, raw_data4, raw_data10)\n",
    "lstm_model = train_model(lstm_model, raw_data5, raw_data10)\n",
    "lstm_model = train_model(lstm_model, raw_data6, raw_data10)\n",
    "#lstm_model = train_model(lstm_model, raw_data7, raw_data10)\n",
    "lstm_model = train_model(lstm_model, raw_data8, raw_data10)\n",
    "lstm_model, conv_window = train_model(lstm_model, raw_data9, raw_data10, window=True)\n",
    "\n",
    "IPython.display.clear_output()\n",
    "val_performance['LSTM split'] = lstm_model.evaluate(conv_window.val)\n",
    "performance['LSTM split'] = lstm_model.evaluate(conv_window.test, verbose=0)\n",
    "\n",
    "lstm_model.save('LSTM_split_flex_to_laz_X')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = np.arange(len(performance))\n",
    "width = 0.3\n",
    "metric_name = 'mean_absolute_error'\n",
    "metric_index = lstm_model.metrics_names.index('mean_absolute_error')\n",
    "val_mae = [v[metric_index] for v in val_performance.values()]\n",
    "test_mae = [v[metric_index] for v in performance.values()]\n",
    "\n",
    "plt.ylabel('mean_absolute_error [Laz, normalized]')\n",
    "plt.bar(x - 0.17, val_mae, width, label='Validation')\n",
    "plt.bar(x + 0.17, test_mae, width, label='Test')\n",
    "plt.xticks(ticks=x, labels=performance.keys(), rotation=45)\n",
    "_ = plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
